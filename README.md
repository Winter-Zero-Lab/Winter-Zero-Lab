<div align="center">
  
  <h1>‚ùÑÔ∏è Winter Lab 0</h1>
  
  <p>
    <strong>De-blackboxing AI, One Equation at a Time.</strong>
  </p>

  <p>
    <img src="https://img.shields.io/badge/Focus-Deep%20Learning%20Theory-FF6F00?style=flat-square" />
    <img src="https://img.shields.io/badge/Focus-System%20Optimization-76B900?style=flat-square" />
    <img src="https://img.shields.io/badge/Status-Undergrad%20Researcher-blue?style=flat-square" />
  </p>

  <br />
</div>

### üî¨ Research & Engineering

I don't just import libraries; I rebuild them to understand the mathematics within.
My goal is to bridge the gap between **Mathematical Intuition** and **System Efficiency**.

| **Core Stack** | **Frameworks** | **Infrastructure** |
| :--- | :--- | :--- |
| ![Python](https://img.shields.io/badge/-Python-3776AB?style=flat&logo=python&logoColor=white) ![C++](https://img.shields.io/badge/-C++-00599C?style=flat&logo=c%2B%2B&logoColor=white) ![CUDA](https://img.shields.io/badge/-CUDA-76B900?style=flat&logo=nvidia&logoColor=white) | ![PyTorch](https://img.shields.io/badge/-PyTorch-EE4C2C?style=flat&logo=pytorch&logoColor=white) ![NumPy](https://img.shields.io/badge/-NumPy-013243?style=flat&logo=numpy&logoColor=white) | ![Linux](https://img.shields.io/badge/-Linux-FCC624?style=flat&logo=linux&logoColor=black) ![Docker](https://img.shields.io/badge/-Docker-2496ED?style=flat&logo=docker&logoColor=white) |

---

### üó∫Ô∏è The Winter Roadmap: From Scratch to SOTA

My open-source journey is divided into three strategic epochs:

#### **Epoch 1: Genesis (Foundations & Architecture)**
*Building the mathematical engine and core neural structures.*
- **üü¢ [WinterGrad](https://github.com/Winter-Zero-Lab/WinterGrad)**: Scalar-valued autograd engine & dynamic computational graph visualization. *(Active)*
- **‚ö™ [Winter-Vision](https://github.com/Winter-Zero-Lab/Winter-Vision)**: Manual implementation of CNNs (`im2col`) and Vision Transformers. *(Planned)*
- **‚ö™ [WinterGPT](https://github.com/Winter-Zero-Lab/WinterGPT)**: Transformer implementation with KV-Cache acceleration. *(Planned)*

#### **Epoch 2: Industrial (System & Generative AI)**
*Optimizing for high-performance inference and parameter-efficient training.*
- **‚ö™ [Winter-Diffusion](https://github.com/Winter-Zero-Lab/Winter-Diffusion)**: DDPM reproduction with custom DDIM ODE sampler. *(Planned)*
- **‚ö™ [Winter-Tuning](https://github.com/Winter-Zero-Lab/Winter-Tuning)**: LoRA/PEFT implementation from scratch for LLM fine-tuning. *(Planned)*
- **üî¥ [Winter-CUDA](https://github.com/Winter-Zero-Lab/Winter-CUDA)**: High-performance matrix multiplication kernels optimized with Tiling & Shared Memory. *(High Priority)*

#### **Epoch 3: Cognition (Agents & Evaluation)**
*Exploring autonomous reasoning and rigorous benchmarking.*
- **‚ö™ [Winter-Agent](https://github.com/Winter-Zero-Lab/Winter-Agent)**: ReAct loop implementation for tool-using LLM agents. *(Planned)*
- **‚ö™ [Winter-Eval](https://github.com/Winter-Zero-Lab/Winter-Eval)**: Automated evaluation framework for model safety and alignment. *(Planned)*

---

<div align="center">
  <img src="https://github-readme-stats.vercel.app/api?username=Winter-Zero-Lab&show_icons=true&theme=gotham&hide_border=true" alt="Winter's Stats" height="150" />
  <img src="https://github-readme-stats.vercel.app/api/top-langs/?username=Winter-Zero-Lab&layout=compact&theme=gotham&hide_border=true" alt="Languages" height="150" />
</div>

<br />

<div align="center">
  <sub>Let the code speak. Contact: <a href="mailto:premamaskaram@gmail.com">premamaskaram@gmail.com</a></sub>
</div>